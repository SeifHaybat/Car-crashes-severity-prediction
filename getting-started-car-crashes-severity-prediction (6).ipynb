{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## You're here! \nWelcome to your first competition in the [ITI's AI Pro training program](https://ai.iti.gov.eg/epita/ai-engineer/)! We hope you enjoy and learn as much as we did prepairing this competition.\n\n\n## Introduction\n\nIn the competition, it's required to predict the `Severity` of a car crash given info about the crash, e.g., location.\n\nThis is the getting started notebook. Things are kept simple so that it's easier to understand the steps and modify it.\n\nFeel free to `Fork` this notebook and share it with your modifications **OR** use it to create your submissions.\n\n### Prerequisites\nYou should know how to use python and a little bit of Machine Learning. You can apply the techniques you learned in the training program and submit the new solutions! \n\n### Checklist\nYou can participate in this competition the way you perefer. However, I recommend following these steps if this is your first time joining a competition on Kaggle.\n\n* Fork this notebook and run the cells in order.\n* Submit this solution.\n* Make changes to the data processing step as you see fit.\n* Submit the new solutions.\n\n*You can submit up to 5 submissions per day. You can select only one of the submission you make to be considered in the final ranking.*\n\n\nDon't hesitate to leave a comment or contact me if you have any question!","metadata":{"papermill":{"duration":0.011447,"end_time":"2021-06-04T18:20:08.51834","exception":false,"start_time":"2021-06-04T18:20:08.506893","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"## Import the libraries\n\nWe'll use `pandas` to load and manipulate the data. Other libraries will be imported in the relevant sections.","metadata":{"papermill":{"duration":0.010174,"end_time":"2021-06-04T18:20:08.539015","exception":false,"start_time":"2021-06-04T18:20:08.528841","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import pandas as pd\nimport os\nimport numpy as np\nfrom sklearn.impute import KNNImputer\n","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":0.020965,"end_time":"2021-06-04T18:20:08.570429","exception":false,"start_time":"2021-06-04T18:20:08.549464","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-27T14:08:39.580885Z","iopub.execute_input":"2021-07-27T14:08:39.581279Z","iopub.status.idle":"2021-07-27T14:08:39.587041Z","shell.execute_reply.started":"2021-07-27T14:08:39.581249Z","shell.execute_reply":"2021-07-27T14:08:39.585947Z"},"trusted":true},"execution_count":236,"outputs":[]},{"cell_type":"markdown","source":"## Exploratory Data Analysis\nIn this step, one should load the data and analyze it. However, I'll load the data and do minimal analysis. You are encouraged to do thorough analysis!\n\nLet's load the data using `pandas` and have a look at the generated `DataFrame`.","metadata":{"papermill":{"duration":0.010591,"end_time":"2021-06-04T18:20:08.592081","exception":false,"start_time":"2021-06-04T18:20:08.58149","status":"completed"},"tags":[]}},{"cell_type":"code","source":"dataset_path = '/kaggle/input/car-crashes-severity-prediction/'\n\ndf = pd.read_csv(os.path.join(dataset_path, 'train.csv'))\n\nwdf = pd.read_csv(os.path.join(dataset_path, 'weather-sfcsv.csv'))\n# print(type(str(wdf[\"Year\"])))\n# wdf[\"date\"] = str(wdf[\"Year\"])+\"-\"+str(wdf[\"Day\"])+\"-\"+str(wdf[\"Month\"])\nwdf['Hour'] = wdf['Hour'].map(int).apply(lambda x: \"{:02d}\".format(x))\nwdf['timestamp'] = wdf[\"Year\"].map(str) +'-'+wdf[\"Month\"].map(str)+'-'+ wdf[\"Day\"].map(str)+\" \"+wdf['Hour'].map(str)\nprint(\"The shape of the dataset is {}.\\n\\n\".format(df.shape))\n\n\n\n\ndf.head()\nwdf.head()\n\n# wdf[wdf['timestamp']=='2019-6-12 08']\n# wdf[wdf['timestamp'].duplicated()  ]and wdf['Wind_Chill(F)'].isna\n# kdf = wdf[wdf['timestamp'].duplicated(keep='first')]\n# kdf['timestamp'].value_counts()\n\n# wdf[wdf['timestamp']=='2019-12-7 15']\n\n# kdf['Wind_Chill(F)'].isna().sum()\n\nwdf =wdf.drop(columns=['Year','Month','Hour','Day','Precipitation(in)','Selected'])\n# wdf['Weather_Condition']= wdf['Weather_Condition'].astype('category')\n# wdf['Weather_Condition'] = wdf['Weather_Condition'].cat.codes\n\n\n# wdf.dropna(subset=['Visibility(mi)'], how='all', inplace=True)\n# wdf.dropna(subset=['Weather_Condition'], how='all', inplace=True)\nwdf['Weather_Condition'] = wdf['Weather_Condition'].map({'Partly Cloudy': 0, 'Mostly Cloudy': 1, 'Fair': 2, 'Overcast': 3, 'Clear': 4, 'Scattered Clouds': 5,'Cloudy': 6, 'Light Rain': 7, 'Fair / Windy': 8, 'Haze': 9, 'Rain': 10, 'Partly Cloudy / Windy': 11, 'Mostly Cloudy / Windy': 12, 'Fog': 13, 'Shallow Fog': 14,'Heavy Rain': 15, 'Smoke': 16, 'Cloudy / Windy': 17, 'Light Rain / Windy':18 , 'Light Drizzle': 19, 'Mist': 20, 'Patches of Fog': 21, 'Rain / Windy': 22, 'Light Thunderstorms and Rain': 23, 'Squalls': 24,'Fog / Windy': 25})\n\n\n# wdf['Weather_Condition'].value_counts()\n\n\n# integrate missing data in wind chill using normal distn\n# index = wdf[wdf['Wind_Chill(F)'].isna()].index\n# value = np.random.normal(loc=wdf['Wind_Chill(F)'].mean(), scale=wdf['Wind_Chill(F)'].std(), size=wdf['Wind_Chill(F)'].isna().sum())\n# wdf['Wind_Chill(F)'].fillna(pd.Series(value, index=index), inplace=True)\nwdf['Wind_Chill(F)'] = wdf['Wind_Chill(F)'].fillna(wdf['Wind_Chill(F)'].mean())\n\n\n# integrate missing data in wind speed using normal distn\n# index = wdf[wdf['Wind_Speed(mph)'].isna()].index\n# value = np.random.normal(loc=wdf['Wind_Speed(mph)'].mean(), scale=wdf['Wind_Speed(mph)'].std(), size=wdf['Wind_Speed(mph)'].isna().sum())\n# wdf['Wind_Speed(mph)'].fillna(pd.Series(value, index=index), inplace=True)\nwdf['Wind_Speed(mph)'] = wdf['Wind_Speed(mph)'].fillna(wdf['Wind_Speed(mph)'].mean())\n\n\n# integrate missing data in Temperature ,Humidity  with mean\n\nwdf['Temperature(F)'] = wdf['Temperature(F)'].fillna(wdf['Temperature(F)'].mean())\nwdf['Humidity(%)'] = wdf['Humidity(%)'].fillna(wdf['Humidity(%)'].mean())\nwdf['Visibility(mi)'] = wdf['Visibility(mi)'].fillna(wdf['Visibility(mi)'].mean())\nwdf['Weather_Condition'] = wdf['Weather_Condition'].fillna('26')\nwdf = wdf.drop_duplicates(subset=['timestamp'], keep='first')\n\nwdf['Weather_Condition'].value_counts()\n# wdf['Weather_Condition'] = wdf['Weather_Condition'].map(str)\n\n# wdf['Weather_Condition'].isna().sum()\nwdf.isna().sum()\n\n\n","metadata":{"execution":{"iopub.status.busy":"2021-07-27T14:08:39.627291Z","iopub.execute_input":"2021-07-27T14:08:39.627706Z","iopub.status.idle":"2021-07-27T14:08:39.747602Z","shell.execute_reply.started":"2021-07-27T14:08:39.627667Z","shell.execute_reply":"2021-07-27T14:08:39.746194Z"},"trusted":true},"execution_count":237,"outputs":[{"name":"stdout","text":"The shape of the dataset is (6407, 16).\n\n\n","output_type":"stream"},{"execution_count":237,"output_type":"execute_result","data":{"text/plain":"Weather_Condition    0\nWind_Chill(F)        0\nTemperature(F)       0\nHumidity(%)          0\nWind_Speed(mph)      0\nVisibility(mi)       0\ntimestamp            0\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"import xml.etree.ElementTree as ET\n\nroot = ET.parse('/kaggle/input/car-crashes-severity-prediction/holidays.xml').getroot()\n\ndf_cols = [\"date\",\"description\"]\nrows= []\n\nfor elem in root:\n#     tag = {}\n    s_row = elem.attrib.get('row')\n    s_date= elem.find('date').text\n    s_description= elem.find('description').text\n    \n    rows.append({\"date\":s_date,\"description\":s_description})\n    \nhdf = pd.DataFrame(rows,columns=df_cols)\nhdf.head()\n","metadata":{"execution":{"iopub.status.busy":"2021-07-27T14:08:39.749527Z","iopub.execute_input":"2021-07-27T14:08:39.749874Z","iopub.status.idle":"2021-07-27T14:08:39.772481Z","shell.execute_reply.started":"2021-07-27T14:08:39.749841Z","shell.execute_reply":"2021-07-27T14:08:39.770989Z"},"trusted":true},"execution_count":238,"outputs":[{"execution_count":238,"output_type":"execute_result","data":{"text/plain":"         date                            description\n0  2012-01-02                           New Year Day\n1  2012-01-16             Martin Luther King Jr. Day\n2  2012-02-20  Presidents Day (Washingtons Birthday)\n3  2012-05-28                           Memorial Day\n4  2012-07-04                       Independence Day","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>description</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2012-01-02</td>\n      <td>New Year Day</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2012-01-16</td>\n      <td>Martin Luther King Jr. Day</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2012-02-20</td>\n      <td>Presidents Day (Washingtons Birthday)</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2012-05-28</td>\n      <td>Memorial Day</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2012-07-04</td>\n      <td>Independence Day</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# merge datafram with weather data\ndf['holiday']=df['timestamp'].str.contains(\"|\".join(hdf['date']))\ndf['timestamp'] = df['timestamp'].map(str).apply(lambda x: x[0:13])\n\n","metadata":{"execution":{"iopub.status.busy":"2021-07-27T14:08:39.775259Z","iopub.execute_input":"2021-07-27T14:08:39.776094Z","iopub.status.idle":"2021-07-27T14:08:39.804713Z","shell.execute_reply.started":"2021-07-27T14:08:39.776043Z","shell.execute_reply":"2021-07-27T14:08:39.803312Z"},"trusted":true},"execution_count":239,"outputs":[]},{"cell_type":"code","source":"\n\n\n# wdf.info()\nwdf['timestamp']=pd.to_datetime(wdf['timestamp'])\ndf['timestamp']=pd.to_datetime(df['timestamp'])\n\n\nmdf = pd.merge(df, wdf, on='timestamp',how='left')\nmdf.dropna(subset=['Visibility(mi)'], how='all', inplace=True)\n","metadata":{"execution":{"iopub.status.busy":"2021-07-27T14:08:39.807048Z","iopub.execute_input":"2021-07-27T14:08:39.807558Z","iopub.status.idle":"2021-07-27T14:08:39.839294Z","shell.execute_reply.started":"2021-07-27T14:08:39.807512Z","shell.execute_reply":"2021-07-27T14:08:39.838066Z"},"trusted":true},"execution_count":240,"outputs":[]},{"cell_type":"markdown","source":"We've got 6407 examples in the dataset with 14 featues, 1 ID, and the `Severity` of the crash.\n\nBy looking at the features and a sample from the data, the features look of numerical and catogerical types. What about some descriptive statistics?","metadata":{"papermill":{"duration":0.011003,"end_time":"2021-06-04T18:20:08.755399","exception":false,"start_time":"2021-06-04T18:20:08.744396","status":"completed"},"tags":[]}},{"cell_type":"code","source":"mdf.drop(columns='ID').describe()","metadata":{"papermill":{"duration":0.083012,"end_time":"2021-06-04T18:20:08.849647","exception":false,"start_time":"2021-06-04T18:20:08.766635","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-27T14:08:39.840538Z","iopub.execute_input":"2021-07-27T14:08:39.840851Z","iopub.status.idle":"2021-07-27T14:08:39.888917Z","shell.execute_reply.started":"2021-07-27T14:08:39.840820Z","shell.execute_reply":"2021-07-27T14:08:39.887879Z"},"trusted":true},"execution_count":241,"outputs":[{"execution_count":241,"output_type":"execute_result","data":{"text/plain":"               Lat          Lng  Distance(mi)     Severity  Wind_Chill(F)  \\\ncount  6407.000000  6407.000000   6407.000000  6407.000000    6407.000000   \nmean     37.765653  -122.405990      0.135189     2.293429      59.851594   \nstd       0.032555     0.028275      0.396360     0.521225       6.549706   \nmin      37.609619  -122.510440      0.000000     1.000000      31.100000   \n25%      37.737096  -122.412210      0.000000     2.000000      59.000000   \n50%      37.768238  -122.404835      0.000000     2.000000      59.762515   \n75%      37.787813  -122.392477      0.041000     3.000000      59.762515   \nmax      37.825626  -122.349734      6.820000     4.000000      98.000000   \n\n       Temperature(F)  Humidity(%)  Wind_Speed(mph)  Visibility(mi)  \ncount      6407.00000  6407.000000      6407.000000     6407.000000  \nmean         59.93899    68.179669        10.864850        9.440442  \nstd           7.94523    16.163415         6.348389        1.647513  \nmin          36.00000    10.000000         0.000000        0.120000  \n25%          54.00000    59.000000         6.000000       10.000000  \n50%          59.00000    70.000000        10.000000       10.000000  \n75%          64.90000    80.000000        15.000000       10.000000  \nmax          98.00000   100.000000        40.300000       10.000000  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Lat</th>\n      <th>Lng</th>\n      <th>Distance(mi)</th>\n      <th>Severity</th>\n      <th>Wind_Chill(F)</th>\n      <th>Temperature(F)</th>\n      <th>Humidity(%)</th>\n      <th>Wind_Speed(mph)</th>\n      <th>Visibility(mi)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>6407.000000</td>\n      <td>6407.000000</td>\n      <td>6407.000000</td>\n      <td>6407.000000</td>\n      <td>6407.000000</td>\n      <td>6407.00000</td>\n      <td>6407.000000</td>\n      <td>6407.000000</td>\n      <td>6407.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>37.765653</td>\n      <td>-122.405990</td>\n      <td>0.135189</td>\n      <td>2.293429</td>\n      <td>59.851594</td>\n      <td>59.93899</td>\n      <td>68.179669</td>\n      <td>10.864850</td>\n      <td>9.440442</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.032555</td>\n      <td>0.028275</td>\n      <td>0.396360</td>\n      <td>0.521225</td>\n      <td>6.549706</td>\n      <td>7.94523</td>\n      <td>16.163415</td>\n      <td>6.348389</td>\n      <td>1.647513</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>37.609619</td>\n      <td>-122.510440</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>31.100000</td>\n      <td>36.00000</td>\n      <td>10.000000</td>\n      <td>0.000000</td>\n      <td>0.120000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>37.737096</td>\n      <td>-122.412210</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>59.000000</td>\n      <td>54.00000</td>\n      <td>59.000000</td>\n      <td>6.000000</td>\n      <td>10.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>37.768238</td>\n      <td>-122.404835</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>59.762515</td>\n      <td>59.00000</td>\n      <td>70.000000</td>\n      <td>10.000000</td>\n      <td>10.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>37.787813</td>\n      <td>-122.392477</td>\n      <td>0.041000</td>\n      <td>3.000000</td>\n      <td>59.762515</td>\n      <td>64.90000</td>\n      <td>80.000000</td>\n      <td>15.000000</td>\n      <td>10.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>37.825626</td>\n      <td>-122.349734</td>\n      <td>6.820000</td>\n      <td>4.000000</td>\n      <td>98.000000</td>\n      <td>98.00000</td>\n      <td>100.000000</td>\n      <td>40.300000</td>\n      <td>10.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"The output shows desciptive statistics for the numerical features, `Lat`, `Lng`, `Distance(mi)`, and `Severity`. I'll use the numerical features to demonstrate how to train the model and make submissions. **However you shouldn't use the numerical features only to make the final submission if you want to make it to the top of the leaderboard.**","metadata":{}},{"cell_type":"markdown","source":"## Data Splitting\n\nNow it's time to split the dataset for the training step. Typically the dataset is split into 3 subsets, namely, the training, validation and test sets. In our case, the test set is already predefined. So we'll split the \"training\" set into training and validation sets with 0.8:0.2 ratio. \n\n*Note: a good way to generate reproducible results is to set the seed to the algorithms that depends on randomization. This is done with the argument `random_state` in the following command* ","metadata":{"papermill":{"duration":0.011808,"end_time":"2021-06-04T18:20:08.89742","exception":false,"start_time":"2021-06-04T18:20:08.885612","status":"completed"},"tags":[]}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n# ,stratify=mdf[['Severity']]\n\ntrain_df, val_df = train_test_split(mdf, test_size=0.2, random_state=42) # Try adding `,stratify=mdf` here\n\nX_train = train_df.drop(columns=['ID', 'Severity'])\ny_train = train_df['Severity']\n\nX_val = val_df.drop(columns=['ID', 'Severity'])\ny_val = val_df['Severity']\n\nprint(val_df)\n","metadata":{"papermill":{"duration":1.125829,"end_time":"2021-06-04T18:20:10.035208","exception":false,"start_time":"2021-06-04T18:20:08.909379","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-27T14:10:07.451822Z","iopub.execute_input":"2021-07-27T14:10:07.452230Z","iopub.status.idle":"2021-07-27T14:10:07.487979Z","shell.execute_reply.started":"2021-07-27T14:10:07.452193Z","shell.execute_reply":"2021-07-27T14:10:07.486916Z"},"trusted":true},"execution_count":251,"outputs":[{"name":"stdout","text":"        ID        Lat         Lng   Bump  Distance(mi)  Crossing  Give_Way  \\\n2488  2488  37.737483 -122.402230  False         0.000     False     False   \n5479  5479  37.733130 -122.412227  False         0.000     False     False   \n2399  2399  37.737400 -122.402270  False         0.407     False     False   \n1330  1330  37.719284 -122.399544  False         0.000     False     False   \n5921  5921  37.761803 -122.405869  False         0.010     False     False   \n...    ...        ...         ...    ...           ...       ...       ...   \n509    509  37.740032 -122.408096  False         0.000     False     False   \n6221  6221  37.807710 -122.367640  False         0.037     False     False   \n4578  4578  37.725469 -122.394187  False         0.106      True     False   \n5437  5437  37.808110 -122.367190  False         0.037     False     False   \n1732  1732  37.723620 -122.401340  False         0.136     False     False   \n\n      Junction  No_Exit  Railway  ...  Side  Severity           timestamp  \\\n2488     False    False    False  ...     R         2 2019-10-21 11:00:00   \n5479     False    False    False  ...     R         2 2019-09-17 18:00:00   \n2399     False    False    False  ...     R         2 2019-08-14 08:00:00   \n1330     False    False    False  ...     R         2 2020-02-13 12:00:00   \n5921      True    False    False  ...     R         2 2016-05-11 18:00:00   \n...        ...      ...      ...  ...   ...       ...                 ...   \n509      False    False    False  ...     R         2 2018-09-20 07:00:00   \n6221     False    False    False  ...     R         3 2018-06-06 12:00:00   \n4578     False    False     True  ...     R         3 2019-06-22 16:00:00   \n5437      True    False    False  ...     R         3 2016-10-25 06:00:00   \n1732     False    False    False  ...     R         2 2017-06-21 08:00:00   \n\n     holiday  Weather_Condition Wind_Chill(F)  Temperature(F) Humidity(%)  \\\n2488   False                2.0     66.000000            66.0        70.0   \n5479   False               11.0     71.000000            71.0        53.0   \n2399   False                2.0     67.000000            67.0        68.0   \n1330   False                1.0     58.000000            58.0        62.0   \n5921   False                0.0     59.762515            60.1        72.0   \n...      ...                ...           ...             ...         ...   \n509    False                0.0     59.762515            59.0        75.0   \n6221   False                1.0     59.762515            62.1        70.0   \n4578   False                2.0     78.000000            78.0        39.0   \n5437   False                9.0     59.762515            64.0        80.0   \n1732   False                0.0     59.762515            64.0        75.0   \n\n      Wind_Speed(mph)  Visibility(mi)  \n2488         6.000000            10.0  \n5479        22.000000            10.0  \n2399         3.000000            10.0  \n1330         6.000000            10.0  \n5921        12.700000            10.0  \n...               ...             ...  \n509         10.813164            10.0  \n6221        16.100000            10.0  \n4578        17.000000            10.0  \n5437        15.000000             6.0  \n1732         4.600000            10.0  \n\n[1282 rows x 23 columns]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"As pointed out eariler, I'll use the numerical features to train the classifier. **However, you shouldn't use the numerical features only to make the final submission if you want to make it to the top of the leaderboard.** ","metadata":{}},{"cell_type":"code","source":"# This cell is used to select the numerical features. IT SHOULD BE REMOVED AS YOU DO YOUR WORK.\nX_train = X_train[['Lat', 'Lng','Weather_Condition','Temperature(F)','Humidity(%)','Wind_Chill(F)','Wind_Speed(mph)','holiday']]\nX_val = X_val[['Lat', 'Lng','Weather_Condition','Temperature(F)','Humidity(%)','Wind_Chill(F)','Wind_Speed(mph)','holiday']]\nprint(X_val)","metadata":{"execution":{"iopub.status.busy":"2021-07-27T14:10:10.842112Z","iopub.execute_input":"2021-07-27T14:10:10.842495Z","iopub.status.idle":"2021-07-27T14:10:10.859984Z","shell.execute_reply.started":"2021-07-27T14:10:10.842457Z","shell.execute_reply":"2021-07-27T14:10:10.858925Z"},"trusted":true},"execution_count":252,"outputs":[{"name":"stdout","text":"            Lat         Lng Weather_Condition  Temperature(F)  Humidity(%)  \\\n2488  37.737483 -122.402230               2.0            66.0         70.0   \n5479  37.733130 -122.412227              11.0            71.0         53.0   \n2399  37.737400 -122.402270               2.0            67.0         68.0   \n1330  37.719284 -122.399544               1.0            58.0         62.0   \n5921  37.761803 -122.405869               0.0            60.1         72.0   \n...         ...         ...               ...             ...          ...   \n509   37.740032 -122.408096               0.0            59.0         75.0   \n6221  37.807710 -122.367640               1.0            62.1         70.0   \n4578  37.725469 -122.394187               2.0            78.0         39.0   \n5437  37.808110 -122.367190               9.0            64.0         80.0   \n1732  37.723620 -122.401340               0.0            64.0         75.0   \n\n      Wind_Chill(F)  Wind_Speed(mph)  holiday  \n2488      66.000000         6.000000    False  \n5479      71.000000        22.000000    False  \n2399      67.000000         3.000000    False  \n1330      58.000000         6.000000    False  \n5921      59.762515        12.700000    False  \n...             ...              ...      ...  \n509       59.762515        10.813164    False  \n6221      59.762515        16.100000    False  \n4578      78.000000        17.000000    False  \n5437      59.762515        15.000000    False  \n1732      59.762515         4.600000    False  \n\n[1282 rows x 8 columns]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"## Model Training\n\nLet's train a model with the data! We'll train a Random Forest Classifier to demonstrate the process of making submissions. ","metadata":{"papermill":{"duration":0.013313,"end_time":"2021-06-04T18:20:10.060544","exception":false,"start_time":"2021-06-04T18:20:10.047231","status":"completed"},"tags":[]}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\n# Create an instance of the classifier\nclassifier = RandomForestClassifier( max_depth=2,random_state=42)\n\n# Train the classifier\nclassifier = classifier.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2021-07-27T14:10:13.590412Z","iopub.execute_input":"2021-07-27T14:10:13.590829Z","iopub.status.idle":"2021-07-27T14:10:13.907475Z","shell.execute_reply.started":"2021-07-27T14:10:13.590795Z","shell.execute_reply":"2021-07-27T14:10:13.906659Z"},"trusted":true},"execution_count":253,"outputs":[]},{"cell_type":"markdown","source":"Now let's test our classifier on the validation dataset and see the accuracy.","metadata":{"papermill":{"duration":0.022394,"end_time":"2021-06-04T18:20:12.327521","exception":false,"start_time":"2021-06-04T18:20:12.305127","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# print(X_val)\n# print(y_val)\nprint(\"The accuracy of the classifier on the validation set is \", (classifier.score(X_val, y_val)))","metadata":{"execution":{"iopub.status.busy":"2021-07-27T14:10:15.948116Z","iopub.execute_input":"2021-07-27T14:10:15.948666Z","iopub.status.idle":"2021-07-27T14:10:15.975659Z","shell.execute_reply.started":"2021-07-27T14:10:15.948629Z","shell.execute_reply":"2021-07-27T14:10:15.974789Z"},"trusted":true},"execution_count":254,"outputs":[{"name":"stdout","text":"The accuracy of the classifier on the validation set is  0.7464898595943837\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Well. That's a good start, right? A classifier that predicts all examples' `Severity` as 2 will get around 0.63. You should get better score as you add more features and do better data preprocessing.","metadata":{"papermill":{"duration":0.022624,"end_time":"2021-06-04T18:20:12.449016","exception":false,"start_time":"2021-06-04T18:20:12.426392","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"## Submission File Generation\n\nWe have built a model and we'd like to submit our predictions on the test set! In order to do that, we'll load the test set, predict the class and save the submission file. \n\nFirst, we'll load the data.","metadata":{"papermill":{"duration":0.023075,"end_time":"2021-06-04T18:20:12.495824","exception":false,"start_time":"2021-06-04T18:20:12.472749","status":"completed"},"tags":[]}},{"cell_type":"code","source":"test_df = pd.read_csv(os.path.join(dataset_path, 'test.csv'))\ntest_df.head()\n\ntest_df['holiday']=test_df['timestamp'].str.contains(\"|\".join(hdf['date']))\n\ntest_df['timestamp'] = test_df['timestamp'].map(str).apply(lambda x: x[0:13])","metadata":{"execution":{"iopub.status.busy":"2021-07-27T14:08:40.331877Z","iopub.execute_input":"2021-07-27T14:08:40.332173Z","iopub.status.idle":"2021-07-27T14:08:40.352690Z","shell.execute_reply.started":"2021-07-27T14:08:40.332145Z","shell.execute_reply":"2021-07-27T14:08:40.351668Z"},"trusted":true},"execution_count":246,"outputs":[]},{"cell_type":"code","source":"\n\ntest_df['timestamp']=pd.to_datetime(df['timestamp'])\ntest_mdf = pd.merge(test_df, wdf, on='timestamp',how=\"left\")\nprint(len(test_mdf['ID']))\nprint(len(test_mdf['ID'].unique()))\ntest_mdf.isna().sum()\n# wdf.dropna(subset=['Visibility(mi)'], how='all', inplace=True)\n# wdf.dropna(subset=['Weather_Condition'], how='all', inplace=True)","metadata":{"papermill":{"duration":0.056131,"end_time":"2021-06-04T18:20:12.568677","exception":false,"start_time":"2021-06-04T18:20:12.512546","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-27T14:08:40.354201Z","iopub.execute_input":"2021-07-27T14:08:40.354539Z","iopub.status.idle":"2021-07-27T14:08:40.389228Z","shell.execute_reply.started":"2021-07-27T14:08:40.354507Z","shell.execute_reply":"2021-07-27T14:08:40.388137Z"},"trusted":true},"execution_count":247,"outputs":[{"name":"stdout","text":"1601\n1601\n","output_type":"stream"},{"execution_count":247,"output_type":"execute_result","data":{"text/plain":"ID                   0\nLat                  0\nLng                  0\nBump                 0\nDistance(mi)         0\nCrossing             0\nGive_Way             0\nJunction             0\nNo_Exit              0\nRailway              0\nRoundabout           0\nStop                 0\nAmenity              0\nSide                 0\ntimestamp            0\nholiday              0\nWeather_Condition    0\nWind_Chill(F)        0\nTemperature(F)       0\nHumidity(%)          0\nWind_Speed(mph)      0\nVisibility(mi)       0\ndtype: int64"},"metadata":{}}]},{"cell_type":"markdown","source":"Note that the test set has the same features and doesn't have the `Severity` column.\nAt this stage one must **NOT** forget to apply the same processing done on the training set on the features of the test set.\n\nNow we'll add `Severity` column to the test `DataFrame` and add the values of the predicted class to it.\n\n**I'll select the numerical features here as I did in the training set. DO NOT forget to change this step as you change the preprocessing of the training data.**","metadata":{"papermill":{"duration":0.01243,"end_time":"2021-06-04T18:20:12.593691","exception":false,"start_time":"2021-06-04T18:20:12.581261","status":"completed"},"tags":[]}},{"cell_type":"code","source":"X_test = test_mdf.drop(columns=['ID'])\n\n\n\n# You should update/remove the next line once you change the features used for training\nX_test = X_test[['Lat', 'Lng','Weather_Condition','Temperature(F)','Humidity(%)','Wind_Chill(F)','Wind_Speed(mph)']]\n\ny_test_predicted = classifier.predict(X_test)\n\ntest_mdf['Severity'] = y_test_predicted\n\ntest_mdf.head()","metadata":{"papermill":{"duration":0.057034,"end_time":"2021-06-04T18:20:12.663409","exception":false,"start_time":"2021-06-04T18:20:12.606375","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-27T14:08:40.390496Z","iopub.execute_input":"2021-07-27T14:08:40.390828Z","iopub.status.idle":"2021-07-27T14:08:40.453895Z","shell.execute_reply.started":"2021-07-27T14:08:40.390797Z","shell.execute_reply":"2021-07-27T14:08:40.452867Z"},"trusted":true},"execution_count":248,"outputs":[{"execution_count":248,"output_type":"execute_result","data":{"text/plain":"     ID        Lat         Lng   Bump  Distance(mi)  Crossing  Give_Way  \\\n0  6407  37.786060 -122.390900  False         0.039     False     False   \n1  6408  37.769609 -122.415057  False         0.202     False     False   \n2  6409  37.807495 -122.476021  False         0.000     False     False   \n3  6410  37.761818 -122.405869  False         0.000     False     False   \n4  6411  37.732350 -122.414100  False         0.670     False     False   \n\n   Junction  No_Exit  Railway  ...  Side           timestamp  holiday  \\\n0      True    False    False  ...     R 2016-03-25 15:00:00    False   \n1     False    False    False  ...     R 2020-05-05 19:00:00    False   \n2     False    False    False  ...     R 2016-09-16 19:00:00    False   \n3      True    False    False  ...     R 2020-03-29 19:00:00    False   \n4     False    False    False  ...     R 2019-10-09 08:00:00    False   \n\n  Weather_Condition Wind_Chill(F)  Temperature(F) Humidity(%)  \\\n0               5.0     59.762515            64.0        58.0   \n1              12.0     57.000000            57.0        83.0   \n2               4.0     59.762515            62.1        80.0   \n3               2.0     58.000000            58.0        70.0   \n4               2.0     58.000000            58.0        65.0   \n\n   Wind_Speed(mph)  Visibility(mi)  Severity  \n0             23.0            10.0         2  \n1             22.0            10.0         2  \n2              9.2            10.0         2  \n3             10.0            10.0         2  \n4              3.0            10.0         2  \n\n[5 rows x 23 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>Lat</th>\n      <th>Lng</th>\n      <th>Bump</th>\n      <th>Distance(mi)</th>\n      <th>Crossing</th>\n      <th>Give_Way</th>\n      <th>Junction</th>\n      <th>No_Exit</th>\n      <th>Railway</th>\n      <th>...</th>\n      <th>Side</th>\n      <th>timestamp</th>\n      <th>holiday</th>\n      <th>Weather_Condition</th>\n      <th>Wind_Chill(F)</th>\n      <th>Temperature(F)</th>\n      <th>Humidity(%)</th>\n      <th>Wind_Speed(mph)</th>\n      <th>Visibility(mi)</th>\n      <th>Severity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>6407</td>\n      <td>37.786060</td>\n      <td>-122.390900</td>\n      <td>False</td>\n      <td>0.039</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>R</td>\n      <td>2016-03-25 15:00:00</td>\n      <td>False</td>\n      <td>5.0</td>\n      <td>59.762515</td>\n      <td>64.0</td>\n      <td>58.0</td>\n      <td>23.0</td>\n      <td>10.0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>6408</td>\n      <td>37.769609</td>\n      <td>-122.415057</td>\n      <td>False</td>\n      <td>0.202</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>R</td>\n      <td>2020-05-05 19:00:00</td>\n      <td>False</td>\n      <td>12.0</td>\n      <td>57.000000</td>\n      <td>57.0</td>\n      <td>83.0</td>\n      <td>22.0</td>\n      <td>10.0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>6409</td>\n      <td>37.807495</td>\n      <td>-122.476021</td>\n      <td>False</td>\n      <td>0.000</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>R</td>\n      <td>2016-09-16 19:00:00</td>\n      <td>False</td>\n      <td>4.0</td>\n      <td>59.762515</td>\n      <td>62.1</td>\n      <td>80.0</td>\n      <td>9.2</td>\n      <td>10.0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6410</td>\n      <td>37.761818</td>\n      <td>-122.405869</td>\n      <td>False</td>\n      <td>0.000</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>R</td>\n      <td>2020-03-29 19:00:00</td>\n      <td>False</td>\n      <td>2.0</td>\n      <td>58.000000</td>\n      <td>58.0</td>\n      <td>70.0</td>\n      <td>10.0</td>\n      <td>10.0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>6411</td>\n      <td>37.732350</td>\n      <td>-122.414100</td>\n      <td>False</td>\n      <td>0.670</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>R</td>\n      <td>2019-10-09 08:00:00</td>\n      <td>False</td>\n      <td>2.0</td>\n      <td>58.000000</td>\n      <td>58.0</td>\n      <td>65.0</td>\n      <td>3.0</td>\n      <td>10.0</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 23 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"Now we're ready to generate the submission file. The submission file needs the columns `ID` and `Severity` only.","metadata":{"papermill":{"duration":0.025364,"end_time":"2021-06-04T18:20:12.713157","exception":false,"start_time":"2021-06-04T18:20:12.687793","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# test_mdf[['ID', 'Severity']].duplicated()\n\ntest_mdf[['ID', 'Severity']].to_csv('/kaggle/working/submission.csv', index=False)","metadata":{"papermill":{"duration":0.031031,"end_time":"2021-06-04T18:20:12.769282","exception":false,"start_time":"2021-06-04T18:20:12.738251","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-27T14:08:40.455175Z","iopub.execute_input":"2021-07-27T14:08:40.455483Z","iopub.status.idle":"2021-07-27T14:08:40.465870Z","shell.execute_reply.started":"2021-07-27T14:08:40.455451Z","shell.execute_reply":"2021-07-27T14:08:40.464805Z"},"trusted":true},"execution_count":249,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The remaining steps is to submit the generated file and are as follows. \n\n1. Press `Save Version` on the upper right corner of this notebook.\n2. Write a `Version Name` of your choice and choose `Save & Run All (Commit)` then click `Save`.\n3. Wait for the saved notebook to finish running the go to the saved notebook.\n4. Scroll down until you see the output files then select the `submission.csv` file and click `Submit`.\n\nNow your submission will be evaluated and your score will be updated on the leaderboard! CONGRATULATIONS!!","metadata":{"papermill":{"duration":0.012446,"end_time":"2021-06-04T18:20:12.795186","exception":false,"start_time":"2021-06-04T18:20:12.78274","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"## Conclusion\n\nIn this notebook, we have demonstrated the essential steps that one should do in order to get \"slightly\" familiar with the data and the submission process. We chose not to go into details in each step to keep the welcoming notebook simple and make a room for improvement.\n\nYou're encourged to `Fork` the notebook, edit it, add your insights and use it to create your submission.","metadata":{"papermill":{"duration":0.012548,"end_time":"2021-06-04T18:20:12.821037","exception":false,"start_time":"2021-06-04T18:20:12.808489","status":"completed"},"tags":[]}}]}